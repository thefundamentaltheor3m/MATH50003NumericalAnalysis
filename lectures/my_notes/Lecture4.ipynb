{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to be able to do analysis in floating point arithmetic systems, we need a way to bound errors *in a precise manner*."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An **absolute error** is going to be some $\\delta_a$ s.t. $$\\tilde{x} = x + \\delta_a$$ (where $\\tilde{x}$ is the true value of the quantity being measured, and $x$ is the measurement). A **relative error** is some $\\delta_r$ s.t. $$\\tilde{x} = x\\left(1 + \\delta_r\\right)$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Epsilon\n",
    "\n",
    "Machine Epsilon is denoted $\\epsilon_{m, s}$ and is defined as $$\\epsilon_{m, s} := 2^{-s}$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divided Differences\n",
    "\n",
    "For example, how does one compute a derivative?\n",
    "\n",
    "What we do is:\n",
    "\n",
    "$$ \\begin{align*}\n",
    "f'(x) &\\approx \\frac{f(x+h) - f(x)}{h} \\\\\n",
    "&\\approx \\left[ f_{\\operatorname{fl}}(x \\oplus h) \\ominus f_{\\operatorname{fl}}(x) \\right] \\oslash h\n",
    "\\end{align*} $$\n",
    "\n",
    "where $h$ is very small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.5",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "name": "julia"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
